{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module 3: Conventional Machine Learning\n",
        "\n",
        "Datasets\n",
        "1. **[Wisconsin breast cancer dataset](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)**\n",
        "2. **[Knee MRI image in the dicom format](https://drive.google.com/file/d/18szKEsfWko9PnuG__SuAVNQLhTVv-1Ha/view?usp=sharing)**"
      ],
      "metadata": {
        "id": "R0YB3J8B_Slk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Classification\n",
        "\n",
        "Useful Packages/Libraries: **numpy, pandas, scikit-learn**\n",
        "\n",
        "**Assignment 3.1**\n",
        "\n",
        "*Our goal is to use different features obtained from the cell nuclei present in the image (e.g. radius, area, smoothness, etc.) to predict whether the given sample/image corresponds to a malignant or a benign tumor.*\n",
        "\n",
        "*   **Load the breast cancer dataset using pandas.**\n",
        "  *  Extract the diagnosis feature values as a numpy array, **Y**\n",
        "  *  Remove the the diagnosis and id features from the dataframe\n",
        "  *  Extract the remaining feature values as a numpy array/matrix, **X**\n",
        "\n",
        "*   **Data setup and preprocessing**\n",
        "  *  Randomly split X into X_train and X_test such that 70% of the data is in X_train and the remaining 30% is in X_test. **Note: Save the split indices**\n",
        "  *  Use the above indices to split Y into Y_train and Y_test. **Hint:** Use the **train_test_split** function from scikit learn to simultaneously do both of these tasks.\n",
        "  *  Scale the data (column-wise) in X_train to zero-mean and unit standard deviation. **Hint:** Use the **StandardScaler** function from sklearn.preprocessing for this task. ***Why do we scale the data?***\n",
        "  *   Use the standard scaler trained on X_train to transform X_test. Why do we do this?\n",
        "\n",
        "*   **Set up the following classifiers**\n",
        "    * SVM (use a linear kernel)\n",
        "    * Decision trees\n",
        "    * Random forest (ntrees=50)\n",
        "    * k nearest neighbors (k=5)\n",
        "    * Logistic regression\n",
        "  \n",
        "  Here is an example code for setting up support vector machines (SVM). Use this as a reference when implementing different classifiers.\n",
        "\n",
        "    ```python\n",
        "    from sklearn.svm import SVC\n",
        "    mySVM = SVC(kernel='linear',probability=True)\n",
        "    ```\n",
        "\n",
        "*   **Train each classifier**\n",
        "\n",
        "  Here is an example for training support vector machines. Use this as a reference to train each classifier.\n",
        "\n",
        "    ```python\n",
        "    mySVM.fit(X_train,Y_train)\n",
        "    ```\n",
        "*   **Evaluate the trained classifiers**. For each classifier, perform the following operations:\n",
        "  *   Calculate true positives, false positives, true negatives and false negatives. *Hint: Use sklearn.predict*\n",
        "  *   Visualize the above values on a confusion matrix.\n",
        "  *   Plot the receiver operating characteristic (ROC) curve. *Hint: use `from sklearn.metrics._plot.roc_curve import plot_roc_curve`*\n",
        "  *   Calculate AUROC: area under the roc curve\n",
        "  *   Plot the precision-recall (PR) curve and calculate AUPRC.\n",
        "  *   Which classifier had the best performance? Which classifier had the worst performance?\n"
      ],
      "metadata": {
        "id": "ZJqW_d6gCAej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 3.1\n",
        "\n",
        "# Load the breast cancer dataset using pandas.\n",
        "\n",
        "# Data setup and preprocessing\n",
        "\n",
        "# Set up the following classifiers\n",
        "\n",
        "# Train each classifier\n",
        "\n",
        "# Evaluate the trained classifiers.\n"
      ],
      "metadata": {
        "id": "bW7jNW3EB_05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Hyperparameter Optimization\n",
        "\n",
        "Useful Packages/Libraries: **numpy, pandas, scikit-learn**\n",
        "\n",
        "**Assignment 3.2**\n",
        "\n",
        "*Our goal is to optimize the classification results obtained in Assignment 3.1*. We will work with the SVM classifier.\n",
        "\n",
        "*   **k-fold cross validation**\n",
        "  *  Perform 10-fold cross validation on X_train and record the results: (Sensitivity, Specificity, AUROC)\n",
        "  \n",
        "    Useful link: [https://scikit-learn.org/0.17/modules/generated/sklearn.cross_validation.KFold.html](https://scikit-learn.org/0.17/modules/generated/sklearn.cross_validation.KFold.html)\n",
        "\n",
        "*   **Working with imbalanced datasets**\n",
        "  *  Use SMOTE to balance the dataset.\n",
        "  ```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=10)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
        "```\n",
        "  *   Perform 10-fold cross validation on the resampled dataset and record the results.\n",
        "  *   Train SVM on the resampled dataset and record the results on the test dataset. What do you observe?\n",
        "  *   Do a literature review to list and describe all the methods that can be used for dealing with imbalanced datasets.\n",
        "\n",
        "*   **Hyperparameter optimization:** Use [GridsearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to optimize the following SVM hyperparameters on X_train\n",
        "  * Kernel: Linear, RBF\n",
        "  * C: 1, 10\n",
        "  Use the following code snippet for initialization\n",
        "  ```python\n",
        "  parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "  ```\n",
        "  * Use the optimal hyperparameters obtained from the above experiment to train a new SVM model on X_train and test it on X_test. What do you observe?\n",
        "\n",
        "*   **Feature selection**:\n",
        "  * Use recursive feature elimination to identify the top features using cross-validation. Use this [link](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py) as reference. **Note: Apply this only to X_train**.\n",
        "  * Use the top features to re-train the model on X_train and evaluate it on X_test. **Note: Do not forget to remove the unused features from X_test**.\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "t64gnk9vbwWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 3.2\n",
        "\n",
        "# k-fold cross validation\n",
        "\n",
        "# Working with imbalanced datasets\n",
        "\n",
        "# Hyperparameter optimization\n",
        "\n",
        "# Feature selection:\n"
      ],
      "metadata": {
        "id": "7r0bW4aAiIU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Clustering\n",
        "\n",
        "Useful Packages/Libraries: **numpy, pandas, scikit-learn**\n",
        "\n",
        "**Assignment 3.3**\n",
        "\n",
        "\n",
        "*   **Load the knee MRI using pydicom**.\n",
        "  * Save 2D array into the variable, K2\n",
        "  * Save shape of K2 as S2\n",
        "  * Flatten the 2D array into a 1D array variable (K11)\n",
        "  * Find the length of the K11, L1\n",
        "  * Reshape K11 to (L1,1)\n",
        "\n",
        "*   **Set up the following clustering algorithms**\n",
        "    * k-means\n",
        "    * mini-batch k-means\n",
        "    * hierarchical clustering\n",
        "    * spectral clustering\n",
        "    \n",
        "    Here is an example code for setting up **k-means**. Use this as a reference when implementing different algorithms.\n",
        "\n",
        "    ```python\n",
        "    from sklearn.cluster import KMeans\n",
        "    myKmeans = KMeans(n_clusters = 3)\n",
        "    ```\n",
        "\n",
        "*   **Fit each clustering algorithm to the data**\n",
        "\n",
        "  Here is an example for **kmeans**.\n",
        "\n",
        "    ```python\n",
        "    myKmeans.fit(K1)\n",
        "    ```\n",
        "*   **Visualize the results**. For each algorithm, perform the following operations:\n",
        "  *   Reshape the clustered array to S2 and visualize the clustered image alongside K2.\n",
        "  *   Try different number of clusters (2-5) and compare the results.\n"
      ],
      "metadata": {
        "id": "HsqJbxsdgvFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment 3.3\n",
        "\n",
        "# Load the knee MRI\n",
        "\n",
        "# Set the clustering algorithms\n",
        "\n",
        "# Fit the clustering algorithms\n",
        "\n",
        "# Visualize the results"
      ],
      "metadata": {
        "id": "4H7uTEm4rjAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Dimensionality Reduction / Representation Learning\n",
        "\n",
        "Useful Packages/Libraries: **numpy, pandas, scikit-learn**\n",
        "\n",
        "**Assignment 3.4**\n",
        "\n",
        "\n",
        "*   **Load the breast cancer data using pandas**.\n",
        "  *  Extract the diagnosis feature values as a numpy array, **Y**\n",
        "  *  Remove the the diagnosis and id features from the dataframe\n",
        "  *  Extract the remaining feature values as a numpy array/matrix, **X**  \n",
        "*   **Scale / Normalize each column in X to zero mean and unit standard deviation**.  \n",
        "  \n",
        "*   **Set up the following dimensionality reduction algorithms with #dimensions = 2**\n",
        "    * pca\n",
        "    * tsne\n",
        "    \n",
        "*   **Fit each dimensionality reduction to X**\n",
        "\n",
        "*   **Visualize the resulting 2-dimensional embeddings using a scatterplot**\n",
        "*   **Colorcode your scatterplot with diagnosis labels**\n",
        "\n"
      ],
      "metadata": {
        "id": "7x3TiohJSAex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment 3.4\n",
        "\n",
        "# Load the breast cancer data\n",
        "\n",
        "# Scale the data\n",
        "\n",
        "# Set up the DR algorithms\n",
        "\n",
        "# Fit the dimensionality reduction algorithms\n",
        "\n",
        "# Visualize the results\n",
        "\n"
      ],
      "metadata": {
        "id": "m0Q4QTMFTF2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}